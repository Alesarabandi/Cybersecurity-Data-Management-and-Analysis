{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Title: Acquisition Phase - Collecting data to come able in Analyzing Global Cyberattack Patterns and Enhanced Cybersecurity.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 🛠️ Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic/Standard libraries to manage data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Necessary libraries to use the api\n",
    "import requests\n",
    "import json\n",
    "from pprint import pprint # for better visualization of json structure\n",
    "\n",
    "# pip install tqdm (only if you haven't installed this library in your pc)\n",
    "from tqdm import tqdm # To add a progress bar when you use a for cycle (useful when you want to take trace of the iterations in a cycle or its execution time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1️⃣ Loading First Data Source \n",
    "#### (Kaggle Dataset: updated_cybersecurity_attacks.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"\"\n",
    "attacks = pd.read_csv(path, delimiter = ',') # First data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the head of our dataset\n",
    "attacks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes the columns\n",
    "attacks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to keep\n",
    "columns_to_keep = [\n",
    "    'Source IP Address', 'Destination IP Address', 'Protocol', 'Packet Type', \n",
    "    'Packet Length', 'Traffic Type', 'Malware Indicators', 'Anomaly Scores', \n",
    "    'Alerts/Warnings', 'Attack Type', 'Action Taken', 'Severity Level', \n",
    "    'Log Source', 'Browser', 'Device/OS', 'Year', 'Month', 'Day'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to keep only the selected columns\n",
    "attacks = attacks[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'Date' by merging Year, Month, and Day\n",
    "attacks['Date'] = pd.to_datetime(attacks[['Year', 'Month', 'Day']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the Year, Month, and Day columns\n",
    "attacks = attacks.drop(columns=['Year', 'Month', 'Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 rows of the updated DataFrame\n",
    "attacks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated shape of our dataset\n",
    "attacks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 🔍 Define & Explore our API (essential element of our second data source)\n",
    "\n",
    "For more Info & Details see below links:\n",
    " \n",
    "[API Landing Page](https://ipgeolocation.io/)\n",
    "\n",
    "[API Documentation](https://ipgeolocation.io/documentation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"\"\n",
    "ip = \"142.250.186.174\" # Example of \"typic\" ip (--> A lot info can be extracted from this ip)\n",
    "#ip = \"10.90.47.5\" # Example of ip for wich isn't possible to extract any information\n",
    "api_base_url = f\"{\"https://api.ipgeolocation.io/ipgeo?apiKey=\"}{API_KEY}{\"&ip=\"}{ip}\"\n",
    "options = \"&fields=geo&include=security\" # Include geolocation and security info\n",
    "users_endpoint = f\"{api_base_url}{options}\"\n",
    "print(f\"Your user edpoint: {users_endpoint}\")\n",
    "response = requests.get(users_endpoint)\n",
    "response = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the structure of our API response\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the nested pice\n",
    "pprint(response[\"security\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2️⃣ Second Data Source \"Generation/Collection\"\n",
    "This section is dedicated to the defenition and usage of two important functions:\n",
    "1. **\"JSON_frame_generation\"** function: A function that given a list of API, return (save) a json flie that contain a huge and important amount of information related at them;\n",
    "2. **\"convert_JSON_to_CSV_DATAFRAME\"** function: Afunction that given a json file as input, convert this input in a dataframe object ad save it as csv file.\n",
    "\n",
    "Notice that:\n",
    "- The first function is important because make we able to collect data more fast and in a more \"reliable\" way. This last observation reguard the fact that the service that we use for collecting data is not free (whe have payed for a specif number of request). We have at disposition only 150000 request and we need to do 80000 of them for collecting the info related at ip of attakers (40000) and the ip of victims (40000). So basically we have about two attempts for collecting our data. \n",
    "\n",
    "- The importance of the second function is related to the fact that we know well the structure of our data and we know well the stracture that we need for our future analysis (EDA). Indeed we need a table as input for our future analysis (that in other cases can be also a ML project, Linear Regression Analysis, Dashboard Creation, Cluster Analysis ecc.), we also know that the structure of our data is almost completely fixed, so for these reasons, we will opt for store our data sources in a relational database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON_frame_generation function - definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JSON_frame_generation(ip_list, API_KEY, saving_path, file_name):\n",
    "\n",
    "    '''\n",
    "    Arguments:\n",
    "    ip_list = A list that contain the ip's for which you want to extract related informations\n",
    "    API_KEY = The KEY of the API\n",
    "    saving_path = The path where you want to save the output (the json file)\n",
    "    file_name = How you want to name the output file\n",
    "\n",
    "    Outupt:\n",
    "    A json file that contain the info related to the input ip's.\n",
    "\n",
    "    This function was implemented to make you able to work with a batch approach.\n",
    "    You can decide to use only a portion of the given list input (e.g. from intex 0 to 100 = ip_list[0:100]).\n",
    "\n",
    "    Step 1 - Choose you usage type\n",
    "    Choose 1: if you want to extract information using a specific portion of input lists (from a to b = ip_list[a:b])\n",
    "    Choose 2: if you want to start ectracting from a specific position in your input lists util the end of the lists (from c until the end = ip_list[c:])\n",
    "    \n",
    "    Step 2 - Set the starting and (eventually) the ending batch position\n",
    "    '''\n",
    "\n",
    "    dict_info_att = {}\n",
    "\n",
    "    print(\"Choose your usage: (1 = from a to b | 2 = from a until the end).\")\n",
    "    use_method = int(input(\"Select 1 (if you need a starting and ending batch position) 2 (if you need only a starting batch position)\"))\n",
    "    if use_method == 1:   \n",
    "        strt_btc_pos = int(input(\"Select the starting batch position: \"))\n",
    "        end_btc_pos = int(input(\"Select the ending batch position: \"))\n",
    "        ip_list = ip_list[strt_btc_pos:end_btc_pos]\n",
    "        print(f\"{\"Number of selected rows:\"} {str(len(ip_list))}\")\n",
    "        print(f\"You start collecting data from row {str(strt_btc_pos)} (included) to row {str(end_btc_pos)} (excluded).\")\n",
    "    elif use_method == 2:\n",
    "        strt_btc_pos = int(input(\"Select the starting batch position: \"))\n",
    "        ip_list = ip_list[strt_btc_pos:]\n",
    "        print(f\"{\"Number of selected rows:\"} {str(len(ip_list))}\")\n",
    "        print(f\"You start collecting data from row {str(strt_btc_pos)} (included) until the end.\")\n",
    "\n",
    "    options = \"&fields=geo&include=security\"\n",
    "\n",
    "    for att_ip in tqdm(ip_list, desc = \"IP's info extraction\"):\n",
    "        api_base_url = f\"{\"https://api.ipgeolocation.io/ipgeo?apiKey=\"}{API_KEY}{\"&ip=\"}{att_ip}\"\n",
    "        options = \"&fields=geo&include=security\"\n",
    "        users_endpoint = f\"{api_base_url}{options}\"\n",
    "        response = requests.get(users_endpoint)\n",
    "        response = response.json()\n",
    "        \n",
    "        if len(response) > 1: \n",
    "            dict_key = response[\"ip\"]\n",
    "        else:\n",
    "            list_message = response[\"message\"].split(\" \")\n",
    "            dict_key = list_message[0].strip(\"'\")\n",
    "\n",
    "        dict_info_att[dict_key] = response\n",
    "\n",
    "    print(\"Saving process has started, please wait...\")\n",
    "    full_path = f\"{saving_path}\\\\{file_name}.json\"\n",
    "    with open(full_path, \"w\") as file:\n",
    "        json.dump(dict_info_att, file, indent=4)\n",
    "    print(f\"Full path: {full_path}\")\n",
    "\n",
    "    return print(\"File saved successfully!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON_frame_generation function - usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attakers ip list\n",
    "att_ip_list = attacks[\"Source IP Address\"]\n",
    "att_ip_list = att_ip_list.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful info about them\n",
    "print(att_ip_list) # See the list \n",
    "print(len(att_ip_list)) # See her lenght\n",
    "print(type(att_ip_list)) # Check that type = list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON_frame_generation function - usage for attakers (extract info from attakers ip's)\n",
    "#API_KEY = \"\"\n",
    "#path = r\"\"\n",
    "#file_name = r\"attakers_json_file\"\n",
    "#JSON_frame_generation(att_ip_list, API_KEY, path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Victims ip list\n",
    "vic_ip_list = attacks[\"Destination IP Address\"]\n",
    "vic_ip_list = vic_ip_list.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful info about them\n",
    "print(vic_ip_list) # See the list\n",
    "print(len(vic_ip_list)) # See her lenght\n",
    "print(type(vic_ip_list)) # Check that type = list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON_frame_generation function - usage for victims (extract info from victims ip's)\n",
    "#API_KEY = \"\"\n",
    "#path = r\"\"\n",
    "#file_name = r\"victims_json_file\"\n",
    "#JSON_frame_generation(vic_ip_list, API_KEY, path, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert_JSON_to_CSV_DATAFRAME function - definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Some useful checks before starting with the definition of the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the json file of the attakers (for example) \n",
    "# To be precise: when you finish with attakers, do the same with the victims\n",
    "path = r\"\"\n",
    "with open(path, \"r\") as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the structure\n",
    "pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the lenght\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the lenght of a single element\n",
    "len(data['103.216.15.12']) # for example the length for '103.216.15.12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the lenght for each element\n",
    "ls = []\n",
    "for ip in data:\n",
    "    count = len(data[ip])\n",
    "    ls.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_16 = 0 # Count the number of element with lenght = 16 (elements/ip's for which we can collect related inforamtions)\n",
    "n_1 = 0 #Count the elment with lenght = 1 (elements/ip's for which isn't possible to collect related inforamtions)\n",
    "ls_other = []\n",
    "for el in ls:\n",
    "    if el == 16:\n",
    "        n_16 += 1\n",
    "    elif el == 1:\n",
    "        n_1 +=1\n",
    "    else:\n",
    "        ls_other.append(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = n_16 + n_1\n",
    "n # if n_16 + n_1 = tot. elements/ip's in the json_file (40000 in our case) --> don't worry, everything is ok !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_JSON_to_CSV_DATAFRAME(full_json_file_path, full_destination_path, are_attakers):\n",
    "\n",
    "    '''\n",
    "    This function take a json file as input and convert it in a dataframe object that will be saved in a csv file.\n",
    "\n",
    "    Arguments:\n",
    "    full_json_file_path = The path (full path with the json file name and his extension .json) where you have saved the json file\n",
    "    full_destination_path = The full path (folder path + file name + .csv) where you want to save the output (the csv file)\n",
    "    are_attakers = True (means that we are considering the json file related to the attakers ip's info) or False (means that we are considering the json file related to the victims ip's info)\n",
    "\n",
    "    Outupt:\n",
    "    A csv file that contain the same informations of the input but stoered in another structure/format.\n",
    "    \n",
    "    Notice that: the form of the output depends by the argument are_attakers, indeed if are_attakers = True then the columns of the output dataframe will have \"att_\" statement as their initial, else there will be \"vic_\".\n",
    "    '''\n",
    "\n",
    "    with open(full_json_file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    if are_attakers == True:\n",
    "\n",
    "        data_structure = {\n",
    "            \"att_ip\":[],\n",
    "            \"att_continent_code\": [],\n",
    "            \"att_continent_name\": [],\n",
    "            \"att_country_code2\": [],\n",
    "            \"att_country_code3\": [],\n",
    "            \"att_country_name\": [],\n",
    "            \"att_country_name_official\": [],\n",
    "            \"att_is_eu\": [],\n",
    "            \"att_state_prov\": [],\n",
    "            \"att_state_code\": [],\n",
    "            \"att_district\": [],\n",
    "            \"att_city\": [],\n",
    "            \"att_zipcode\": [],\n",
    "            \"att_latitude\": [],\n",
    "            \"att_longitude\": [],\n",
    "            \"att_threat_score\": [],\n",
    "            \"att_is_tor\": [],\n",
    "            \"att_is_proxy\": [],\n",
    "            \"att_proxy_type\": [],\n",
    "            \"att_is_anonymous\": [],\n",
    "            \"att_is_known_attacker\": [],\n",
    "            \"att_is_spam\": [],\n",
    "            \"att_is_bot\": [],\n",
    "            \"att_is_cloud_provider\": [],\n",
    "            \"att_message\" : []\n",
    "            }\n",
    "        \n",
    "        for ip_key in tqdm(data, desc = \"Processing attakers data...\"):\n",
    "\n",
    "            if len(data[ip_key]) == 16:\n",
    "\n",
    "                data_structure[\"att_ip\"].append(data[ip_key][\"ip\"])\n",
    "                data_structure[\"att_continent_code\"].append(data[ip_key][\"continent_code\"])\n",
    "                data_structure[\"att_continent_name\"].append(data[ip_key][\"continent_name\"])\n",
    "                data_structure[\"att_country_code2\"].append(data[ip_key][\"country_code2\"])\n",
    "                data_structure[\"att_country_code3\"].append(data[ip_key][\"country_code3\"])\n",
    "                data_structure[\"att_country_name\"].append(data[ip_key][\"country_name\"])\n",
    "                data_structure[\"att_country_name_official\"].append(data[ip_key][\"country_name_official\"])\n",
    "                data_structure[\"att_is_eu\"].append(data[ip_key][\"is_eu\"])\n",
    "                data_structure[\"att_state_prov\"].append(data[ip_key][\"state_prov\"])\n",
    "                data_structure[\"att_state_code\"].append(data[ip_key][\"state_code\"])\n",
    "                data_structure[\"att_district\"].append(data[ip_key][\"district\"])\n",
    "                data_structure[\"att_city\"].append(data[ip_key][\"city\"])\n",
    "                data_structure[\"att_zipcode\"].append(data[ip_key][\"zipcode\"])\n",
    "                data_structure[\"att_latitude\"].append(data[ip_key][\"latitude\"])\n",
    "                data_structure[\"att_longitude\"].append(data[ip_key][\"longitude\"])\n",
    "                data_structure[\"att_threat_score\"].append(data[ip_key][\"security\"][\"threat_score\"])\n",
    "                data_structure[\"att_is_tor\"].append(data[ip_key][\"security\"][\"is_tor\"])\n",
    "                data_structure[\"att_is_proxy\"].append(data[ip_key][\"security\"][\"is_proxy\"])\n",
    "                data_structure[\"att_proxy_type\"].append(data[ip_key][\"security\"][\"proxy_type\"])\n",
    "                data_structure[\"att_is_anonymous\"].append(data[ip_key][\"security\"][\"is_anonymous\"])\n",
    "                data_structure[\"att_is_known_attacker\"].append(data[ip_key][\"security\"][\"is_known_attacker\"])\n",
    "                data_structure[\"att_is_spam\"].append(data[ip_key][\"security\"][\"is_spam\"])\n",
    "                data_structure[\"att_is_bot\"].append(data[ip_key][\"security\"][\"is_bot\"])\n",
    "                data_structure[\"att_is_cloud_provider\"].append(data[ip_key][\"security\"][\"is_cloud_provider\"])\n",
    "                data_structure[\"att_message\"].append(\"\")\n",
    "\n",
    "            else:\n",
    "\n",
    "                data_structure[\"att_ip\"].append(\"\")\n",
    "                data_structure[\"att_continent_code\"].append(\"\")\n",
    "                data_structure[\"att_continent_name\"].append(\"\")\n",
    "                data_structure[\"att_country_code2\"].append(\"\")\n",
    "                data_structure[\"att_country_code3\"].append(\"\")\n",
    "                data_structure[\"att_country_name\"].append(\"\")\n",
    "                data_structure[\"att_country_name_official\"].append(\"\")\n",
    "                data_structure[\"att_is_eu\"].append(\"\")\n",
    "                data_structure[\"att_state_prov\"].append(\"\")\n",
    "                data_structure[\"att_state_code\"].append(\"\")\n",
    "                data_structure[\"att_district\"].append(\"\")\n",
    "                data_structure[\"att_city\"].append(\"\")\n",
    "                data_structure[\"att_zipcode\"].append(\"\")\n",
    "                data_structure[\"att_latitude\"].append(\"\")\n",
    "                data_structure[\"att_longitude\"].append(\"\")\n",
    "                data_structure[\"att_threat_score\"].append(\"\")\n",
    "                data_structure[\"att_is_tor\"].append(\"\")\n",
    "                data_structure[\"att_is_proxy\"].append(\"\")\n",
    "                data_structure[\"att_proxy_type\"].append(\"\")\n",
    "                data_structure[\"att_is_anonymous\"].append(\"\")\n",
    "                data_structure[\"att_is_known_attacker\"].append(\"\")\n",
    "                data_structure[\"att_is_spam\"].append(\"\")\n",
    "                data_structure[\"att_is_bot\"].append(\"\")\n",
    "                data_structure[\"att_is_cloud_provider\"].append(\"\")\n",
    "                data_structure[\"att_message\"].append(\"message\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        data_structure = {\n",
    "            \"vic_ip\":[],\n",
    "            \"vic_continent_code\": [],\n",
    "            \"vic_continent_name\": [],\n",
    "            \"vic_country_code2\": [],\n",
    "            \"vic_country_code3\": [],\n",
    "            \"vic_country_name\": [],\n",
    "            \"vic_country_name_official\": [],\n",
    "            \"vic_is_eu\": [],\n",
    "            \"vic_state_prov\": [],\n",
    "            \"vic_state_code\": [],\n",
    "            \"vic_district\": [],\n",
    "            \"vic_city\": [],\n",
    "            \"vic_zipcode\": [],\n",
    "            \"vic_latitude\": [],\n",
    "            \"vic_longitude\": [],\n",
    "            \"vic_threat_score\": [],\n",
    "            \"vic_is_tor\": [],\n",
    "            \"vic_is_proxy\": [],\n",
    "            \"vic_proxy_type\": [],\n",
    "            \"vic_is_anonymous\": [],\n",
    "            \"vic_is_known_attacker\": [],\n",
    "            \"vic_is_spam\": [],\n",
    "            \"vic_is_bot\": [],\n",
    "            \"vic_is_cloud_provider\": [],\n",
    "            \"vic_message\" : []\n",
    "            }\n",
    "        \n",
    "        for ip_key in tqdm(data, desc = \"Processing victims data...\"):\n",
    "\n",
    "            if len(data[ip_key]) == 16:\n",
    "\n",
    "                data_structure[\"vic_ip\"].append(data[ip_key][\"ip\"])\n",
    "                data_structure[\"vic_continent_code\"].append(data[ip_key][\"continent_code\"])\n",
    "                data_structure[\"vic_continent_name\"].append(data[ip_key][\"continent_name\"])\n",
    "                data_structure[\"vic_country_code2\"].append(data[ip_key][\"country_code2\"])\n",
    "                data_structure[\"vic_country_code3\"].append(data[ip_key][\"country_code3\"])\n",
    "                data_structure[\"vic_country_name\"].append(data[ip_key][\"country_name\"])\n",
    "                data_structure[\"vic_country_name_official\"].append(data[ip_key][\"country_name_official\"])\n",
    "                data_structure[\"vic_is_eu\"].append(data[ip_key][\"is_eu\"])\n",
    "                data_structure[\"vic_state_prov\"].append(data[ip_key][\"state_prov\"])\n",
    "                data_structure[\"vic_state_code\"].append(data[ip_key][\"state_code\"])\n",
    "                data_structure[\"vic_district\"].append(data[ip_key][\"district\"])\n",
    "                data_structure[\"vic_city\"].append(data[ip_key][\"city\"])\n",
    "                data_structure[\"vic_zipcode\"].append(data[ip_key][\"zipcode\"])\n",
    "                data_structure[\"vic_latitude\"].append(data[ip_key][\"latitude\"])\n",
    "                data_structure[\"vic_longitude\"].append(data[ip_key][\"longitude\"])\n",
    "                data_structure[\"vic_threat_score\"].append(data[ip_key][\"security\"][\"threat_score\"])\n",
    "                data_structure[\"vic_is_tor\"].append(data[ip_key][\"security\"][\"is_tor\"])\n",
    "                data_structure[\"vic_is_proxy\"].append(data[ip_key][\"security\"][\"is_proxy\"])\n",
    "                data_structure[\"vic_proxy_type\"].append(data[ip_key][\"security\"][\"proxy_type\"])\n",
    "                data_structure[\"vic_is_anonymous\"].append(data[ip_key][\"security\"][\"is_anonymous\"])\n",
    "                data_structure[\"vic_is_known_attacker\"].append(data[ip_key][\"security\"][\"is_known_attacker\"])\n",
    "                data_structure[\"vic_is_spam\"].append(data[ip_key][\"security\"][\"is_spam\"])\n",
    "                data_structure[\"vic_is_bot\"].append(data[ip_key][\"security\"][\"is_bot\"])\n",
    "                data_structure[\"vic_is_cloud_provider\"].append(data[ip_key][\"security\"][\"is_cloud_provider\"])\n",
    "                data_structure[\"vic_message\"].append(\"\")\n",
    "\n",
    "            else:\n",
    "\n",
    "                data_structure[\"vic_ip\"].append(\"\")\n",
    "                data_structure[\"vic_continent_code\"].append(\"\")\n",
    "                data_structure[\"vic_continent_name\"].append(\"\")\n",
    "                data_structure[\"vic_country_code2\"].append(\"\")\n",
    "                data_structure[\"vic_country_code3\"].append(\"\")\n",
    "                data_structure[\"vic_country_name\"].append(\"\")\n",
    "                data_structure[\"vic_country_name_official\"].append(\"\")\n",
    "                data_structure[\"vic_is_eu\"].append(\"\")\n",
    "                data_structure[\"vic_state_prov\"].append(\"\")\n",
    "                data_structure[\"vic_state_code\"].append(\"\")\n",
    "                data_structure[\"vic_district\"].append(\"\")\n",
    "                data_structure[\"vic_city\"].append(\"\")\n",
    "                data_structure[\"vic_zipcode\"].append(\"\")\n",
    "                data_structure[\"vic_latitude\"].append(\"\")\n",
    "                data_structure[\"vic_longitude\"].append(\"\")\n",
    "                data_structure[\"vic_threat_score\"].append(\"\")\n",
    "                data_structure[\"vic_is_tor\"].append(\"\")\n",
    "                data_structure[\"vic_is_proxy\"].append(\"\")\n",
    "                data_structure[\"vic_proxy_type\"].append(\"\")\n",
    "                data_structure[\"vic_is_anonymous\"].append(\"\")\n",
    "                data_structure[\"vic_is_known_attacker\"].append(\"\")\n",
    "                data_structure[\"vic_is_spam\"].append(\"\")\n",
    "                data_structure[\"vic_is_bot\"].append(\"\")\n",
    "                data_structure[\"vic_is_cloud_provider\"].append(\"\")\n",
    "                data_structure[\"vic_message\"].append(\"message\")\n",
    "\n",
    "    df = pd.DataFrame(data_structure)   \n",
    "    df.to_csv(full_destination_path, index = False)\n",
    "    print(\"File successfully saved!!!\")\n",
    "\n",
    "    return print(f\"{\"Your file location:\"}{full_destination_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert_JSON_to_CSV_DATAFRAME function - usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usage for the attakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_JSON_to_CSV_DATAFRAME function - usage for attakers\n",
    "#json_file_path = r\"\"\n",
    "csv_df_destination_path = r\"\"\n",
    "#are_attakers = True\n",
    "#convert_JSON_to_CSV_DATAFRAME(json_file_path, csv_df_destination_path, are_attakers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Test and see the outpt for the attakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the csv file\n",
    "attakers_csv = pd.read_csv(csv_df_destination_path, delimiter = ',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First look on the output \n",
    "attakers_csv.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the shape (row x columns)\n",
    "attakers_csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extratc the names of the all columns\n",
    "attakers_csv.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usage for the victims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_JSON_to_CSV_DATAFRAME function - usage for victims\n",
    "#json_file_path = r\"\"\n",
    "csv_df_destination_path = r\"\"\n",
    "#are_attakers = False\n",
    "#convert_JSON_to_CSV_DATAFRAME(json_file_path, csv_df_destination_path, are_attakers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Test and see the outpt for the victims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the csv file\n",
    "victims_csv = pd.read_csv(csv_df_destination_path, delimiter = ',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First look on the output \n",
    "victims_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the shape (row x columns)\n",
    "victims_csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extratc the names of the all columns\n",
    "victims_csv.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ⏭️ Next Step: \n",
    "$\\rightarrow$ Data Storage, Integration and Enrichment (see 2_dataStorage_Integration_Enrichment_withPostgreSQL.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
